{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bBLbXm3xti75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dlib\n",
    "from pygame import mixer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"Eye_tracking_CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NbNeuBzr5_mI"
   },
   "outputs": [],
   "source": [
    "categories = [\"Closed\",\"Open\"]\n",
    "\n",
    "def prepare(img):\n",
    "    image_size = 100\n",
    "    new_array = cv2.resize(img, (image_size, image_size))\n",
    "    return new_array.reshape(-1, image_size, image_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_alarm():\n",
    "    mixer.init()\n",
    "    mixer.music.load(r\"C:\\Users\\Deboparna Banerjee\\Music\\AGUST D.mp3\")\n",
    "    mixer.music.set_volume(0.1)\n",
    "    mixer.music.play()\n",
    "    \n",
    "    ## pause for 5s\n",
    "    clock = time.time()\n",
    "    while True:\n",
    "        if time.time() - clock >= 5:\n",
    "            break\n",
    "            \n",
    "    ## stop alarm\n",
    "    mixer.music.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # left = [36, 37, 38, 39, 40, 41] # keypoint indices for left eye\n",
    "# # right = [42, 43, 44, 45, 46, 47] # keypoint indices for right eye\n",
    "# display = {\n",
    "#     0 : 'Closed',\n",
    "#     1 : 'Open'\n",
    "# }\n",
    "\n",
    "# def eye_detector(img, flag):\n",
    "#     detector = dlib.get_frontal_face_detector()\n",
    "#     predictor = dlib.shape_predictor('shape_68.dat')\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     faces = detector(gray)\n",
    "#     for face in faces:\n",
    "#         landmarks = predictor(gray, face)\n",
    "\n",
    "#         ## left eye mark\n",
    "#         x1_l = landmarks.part(36).x - 10\n",
    "#         y1_l = landmarks.part(38).y - 10\n",
    "#         x2_l = landmarks.part(39).x + 10\n",
    "#         y2_l = landmarks.part(40).y + 10\n",
    "#         cv2.rectangle(img,(x1_l,y1_l),(x2_l,y2_l),(255,0,0),2)\n",
    "#         left_eye = gray[y1_l:y2_l, x1_l:x2_l]\n",
    "#         prediction_left = model.predict([prepare(left_eye)])\n",
    "#         img=cv2.putText(img, display[int(prediction_left[0][0])], (x1_l, y1_l-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "#         ## right eye mark\n",
    "#         x1_r = landmarks.part(42).x - 10\n",
    "#         y1_r = landmarks.part(44).y - 10\n",
    "#         x2_r = landmarks.part(45).x + 10\n",
    "#         y2_r = landmarks.part(46).y + 10\n",
    "#         cv2.rectangle(img,(x1_r,y1_r),(x2_r,y2_r),(255,0,0),2)\n",
    "#         right_eye = gray[y1_r:y2_r, x1_r:x2_r]\n",
    "#         prediction_right = model.predict([prepare(right_eye)])\n",
    "#         img=cv2.putText(img, display[int(prediction_right[0][0])], (x1_r, y1_r-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "#         if int(prediction_right[0][0]) == int(prediction_left[0][0]) == 0:\n",
    "#             flag['close_frame_count'] += 1\n",
    "#         else:\n",
    "#             flag['close_frame_count'] = 0\n",
    "        \n",
    "#         if flag['close_frame_count'] >= 10:\n",
    "#             img=cv2.putText(img, \"ALERT BITCH\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#         if flag['close_frame_count'] >= 12:\n",
    "#             play_alarm()\n",
    "#             flag['close_frame_count'] = 0\n",
    "                \n",
    "#     img=cv2.putText(img, \"Time Frame: \"+str(flag['close_frame_count']), (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#     return img, flag\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# flag = {\n",
    "#     'close_frame_count' : 0,\n",
    "# }\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     result_img, flag = eye_detector(frame, flag)\n",
    "#     cv2.imshow('Are you drowsy?', result_img)\n",
    "#     if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "#         break\n",
    "        \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left = [36, 37, 38, 39, 40, 41] # keypoint indices for left eye\n",
    "# right = [42, 43, 44, 45, 46, 47] # keypoint indices for right eye\n",
    "display = {\n",
    "    0 : 'Closed',\n",
    "    1 : 'Open'\n",
    "}\n",
    "\n",
    "def eye_detector(img):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_68.dat')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        ## left eye mark\n",
    "        x1_l = landmarks.part(36).x - 10\n",
    "        y1_l = landmarks.part(38).y - 10\n",
    "        x2_l = landmarks.part(39).x + 10\n",
    "        y2_l = landmarks.part(40).y + 10\n",
    "        cv2.rectangle(img,(x1_l,y1_l),(x2_l,y2_l),(255,0,0),2)\n",
    "        left_eye = gray[y1_l:y2_l, x1_l:x2_l]\n",
    "        prediction_left = model.predict([prepare(left_eye)])\n",
    "        img=cv2.putText(img, display[int(prediction_left[0][0])], (x1_l, y1_l-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        ## right eye mark\n",
    "        x1_r = landmarks.part(42).x - 10\n",
    "        y1_r = landmarks.part(44).y - 10\n",
    "        x2_r = landmarks.part(45).x + 10\n",
    "        y2_r = landmarks.part(46).y + 10\n",
    "        cv2.rectangle(img,(x1_r,y1_r),(x2_r,y2_r),(255,0,0),2)\n",
    "        right_eye = gray[y1_r:y2_r, x1_r:x2_r]\n",
    "        prediction_right = model.predict([prepare(right_eye)])\n",
    "        img=cv2.putText(img, display[int(prediction_right[0][0])], (x1_r, y1_r-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "                \n",
    "    return img\n",
    "\n",
    "frame = cv2.imread(r\"C:\\Users\\Deboparna Banerjee\\Desktop\\College\\Sem6\\software engineering\\project\\dataset_drowsiness\\train\\no_yawn\\frame0 (2).jpg\", )\n",
    "cv2.imshow('Are you drowsy?', eye_detector(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Drowsiness CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
